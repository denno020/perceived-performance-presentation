<section>
  <section>
    <h2>Local Data Cache</h2>
    <ul>
      <li class="fragment">Remember what user has already seen</li>
      <li class="fragment">Use cached data while getting an update from server</li>
      <li class="fragment">Demo <sup>4</sup></li>

    </ul>
    <aside class="notes">
      <ul>
        <li>
          As an extension of loading indicators, I want to talk about local data
          cache
        </li>
        <li>
          Now they aren't really related, however the use of local data cache will
          mean that we can prevent our users from having to see loading indicators
          more than necessary
        </li>
        <li>
          and by introducing it now, I can bridge the gap to the patterns we'll
          talk about in a few minutes
        </li>
        <li>
          Local data cache is simply ðŸ–± remembering what the user has already seen,
          and never showing a loading indicator in those contexts again
        </li>
        <li>ðŸ“º Let's refer back to our demo (2) app again</li>
        <li>
          ðŸ“º First, I click on a product on the category page, the API request is
          fired off to get the product information, then when a response is
          returned, we'll render that product data
        </li>
        <li>
          ðŸ“º If I then press the back button, and select the exact same product,
          notice how we're waiting for the product data to download again?
        </li>
        <li>
          ðŸ“º We did also see a loading indicator for the category page, to show
          products that we're already seen
        </li>
        <li>
          ðŸ“º There's no need for either of those loading indicators, we should be
          able to immediately render the same product data that we've already
          downloaded, and then in the background, send off the APi request to get
          updated product information, which we can then choose to render to the
          UI or just update our cache value
        </li>
        <li>
          ðŸ“º This is the stale-while-revalidate pattern that you might have heard
          before
        </li>
        <li>
          ðŸ“º In my day-to-day working on ecommerce websites, we use Apollo Client,
          which automatically handles caching data, serving up that data from
          cache when it's requested, and also updating the cache and pushing
          updated values to render to the UI, so it's super easy to take advantage
          of this pattern
        </li>
        <li>
          ðŸ“º In this next demo (4), however, I'm not using
          Apollo or any other libraries, but rather I've simply written something
          with vanilla JS, using in memory cache
        </li>
        <li>
          ðŸ“º As we can see, the first time that we navigate to the product page, we
          do wait a moment for the request to resolve, but the second, third or
          any other time in the future, we see the product data instantly
        </li>
        <li>
          ðŸ“º The user doesn't need to wait again, and because we're still making the
          same API request to get the product data, they won't be stuck with stale
          data
        </li>
      </ul>
    </aside>
  </section>
  <section>
    <h2>Local Data Cache</h2>
    <ul>
      <li>Implementation</li>
      <li class="fragment">Save to cache
        <pre><code data-trim data-noescape>
        cache.addToCache({ 
          key: `product-${productId}`,
          value: JSON.stringify(res.product)
        })
      </code></pre>
      </li>
      <li class="fragment">Read from cache
        <pre><code data-trim data-noescape>
      const [product, setProduct] = useState(() => {
        const cachedProduct = cache.getItem(`product-${productId}`);
        if (cachedProduct) return cachedProduct;
        return undefined;
      });
    </code></pre>
      </li>

    </ul>
    <aside class="notes">
      <ul>
        <li>Now I did say that the actual code wasn't the important part of this talk, but I wanted to show just how
          straight forward it is to set up this pattern using vanilla JS and your library of choice</li>
        <li>ðŸ–± This is the code that I've used to implement cache</li>
        <li>There's no magic within cache, it's just a singleton that has some methods on it to set and get items</li>
        <li>ðŸ–± Then to read from cache and initialise state.</li>
        <li>As I mentioned earlier, I'm using React to render the app, so that's why the use of useState here</li>
      </ul>
    </aside>
  </section>
  <section>
    <h2>Local Data Cache</h2>
    <ul>
      <li class="fragment">In memory or persisted</li>
      <li class="fragment">
        How to persist
        <ul>
          <li class="fragment">localStorage</li>
          <li class="fragment">sessionStorage</li>
          <li class="fragment">IndexedDB</li>
          <li class="fragment">Cache API</li>
        </ul>
      </li>
      <li class="fragment">Swap cache object for read/write to storage location</li>
    </ul>
    <aside class="notes">
      <ul>
        <li>
          Local data cache can either be the method I just used, store all in
          memory, meaning if a user leaves the website and comes back, or maually
          refreshes the page, all of that cache is cleared
        </li>
        <li>ðŸ–± or persisted onto the users device</li>
        <li>
          Persistence is a great idea, because it gives return visitors immediate
          perceived performance, but we do have to factor in things like available
          storage on the users device
        </li>
        <li>
          ðŸ–± We're not storing compressed data, meaning the space on disk can't be
          minimised like it is within the network transfer to download the dta, so
          we have to be wary to pick a technology that affords us enough space
        </li>
        <li>
          The obvious options would be ðŸ–± localStorage or ðŸ–± sessionStorage, but be
          aware that there is a limit of only around 5mb that can be stored in
          these locations
        </li>
        <li>
          A better approach could actually be ðŸ–± IndexedDB, or if you have a service
          worker installed, the ðŸ–± Cache API, both of which have access to much, much
          more storage space
        </li>
        <li>
          Then we just ned to swap out our in memory cache singleton for an interface to the storage method of choice
        </li>
      </ul>
    </aside>
  </section>
</section>