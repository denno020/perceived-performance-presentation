<section>
  <section>
    <h2>Pre-fetching</h2>
    <ul>
      <li class="fragment">Prevent users from waiting<span class="fragment">, <em>at all</em></span></li>
      <li class="fragment">Any resource can be pre-fetched<span class="fragment">, but</span></li>
      <li class="fragment">Best to stick to just data/text</li>
      <li class="fragment">Skip images/media, unless absolutely sure</li>
      <li class="fragment">Demo <sup>5</sup></li>
      <li class="fragment">Downsides?
        <ul>
          <li class="fragment">Increased bandwidth</li>
          <li class="fragment">Storage limitations</li>
          <li class="fragment">Users on slow connections</li>
        </ul>
      </li>
    </ul>
    <aside class="notes">
      <ul>
        <li>
          Now that we have introduced our local data cache, we can talk about the
          next pattern, pre-fetching
        </li>
        <li>
          The goal of this pattern is to ðŸ–± prevent the user from having to wait ðŸ–± at
          all, giving the user the experience of visiting the product page the
          second time, but without having yet visited it
        </li>
        <li>
          Pre-fetching is simply downloading resources before the user has asked
          for them, so that when they are asked for, they're already downloaded
          and can be instantly shown to the user
        </li>
        <li>What kinds of things could we pre-fetch?</li>
        <li>
          ðŸ–± Literally anything can be pre-fetched,ðŸ–± however we do want to consider
          our users experience and situation before going ahead and pre-fetching
          everything
        </li>
        <li>
          ðŸ–± For example, optimistically pre-fetching data is perfectly fine. That
          data will be compressed on the server and then send to the browser to be
          uncompressed and rendered
        </li>
        <li>
          That data could include a second page of products, or a specific
          products data
        </li>
        <li>
          Pre-fetching JS/CSS files could also be a good option, especially if
          we've made use of code splitting, and we can anticipate the next route
          that a user is going to go to
        </li>
        <li>
          ðŸ–± Pre-fetching image and other media, however, carries a lot more weight
          in terms of bandwidth, so it would usually be a bad idea to pre-fetch,
          especially if we're not sure if the user is definitely going to see it
        </li>
        <li>
          If we know that the user absolutely has to see the image or media in
          order to continue, then go right ahead and pre-fetch, but otherwise it's
          not a good idea to optimistically pre-fetch images or other media
        </li>
        <li>DEMO</li>
        <li>ðŸ–± Are there any downsides to pre-fetching?</li>
        <li>
          ðŸ–± Pre-feetching is using more of the users downloda bandwith, however if
          we're sticking only to downloading data, and that data is compressed on
          the server before being passed to the browser, then that bandwidth
          increase will usually be negligible
        </li>
        <li>
          Consider keeping track of what has been pre-fetched, so you're not
          pre-fetching the same thing twice
        </li>
        <li>ðŸ–± As mentioned earlier, there are storage limitations within the browser</li>
        <li>ðŸ–± A user is on a slow connection</li>
        <li>
          In this instance, we might want to alter our pre-fetching strategy depending on the users
          connection.
        </li>
        <li>
          For example, if they have a good connection, then we might be a little
          more optimistic in pre-fetching, but if they have a poor connection,
          then we might be a little more conservative ðŸ–± 
        </li>
      </ul>
    </aside>
  </section>
  <section>
    <h2>Pre-fetching - Slow Network</h2>
    <ul>
      <li>Network Information API</li>
      <li class="fragment">
        effectiveType
        <ul>
          <li class="fragment">slow-2g</li>
          <li class="fragment">2g</li>
          <li class="fragment">3g</li>
          <li class="fragment">4g</li>
        </ul>
      </li>
      <li class="fragment">type</li>
      <li class="fragment">saveData</li>
    </ul>
    <aside class="notes">
      <li>
        We can check the users connection using the Network Information API,
        which exposes the property ðŸ–± effectiveType.
      </li>
      <li>This will give a value of ðŸ–± "slow-2g", ðŸ–± "2g", ðŸ–± "3g" or ðŸ–± "4g".</li>
      <li>
        We could also use the ðŸ–± type value to determine if the user is likely on a
        metered connection or not
      </li>
      <li>A combination of these parameters will give us a reasonable understanding of the connection that the user is current working with</li>
      <li>
        Another property that is available on the Network Information API is
        ðŸ–± saveData, which tells the browser if the user has explicitly said that
        they are saving data, in which case, as responsible developers, we would
        disable any pre-fetching.
      </li>
    </aside>
  </section>
  <section>
    <h2>Pre-fetching</h2>
    <ul>
      <li>Prevent users from waiting<span>, <em>at all</em></span></li>
      <li>Any resource can be pre-fetched<span>, but</span></li>
      <li>Best to stick to just data/text</li>
      <li>Skip images/media, unless absolutely sure</li>
      <li>Demo <sup>5</sup></li>
      <li>Downsides?
        <ul>
          <li>Increased bandwidth</li>
          <li>Storage limitations</li>
          <li>Users on slow connections</li>
          <li class="fragment">Strain on server</li>
        </ul>
      </li>
    </ul>
    <aside class="notes">
      <li>Will these extra requests strain the server?</li>
      <li>They certainly could, especially at scale</li>
      <li>
        However, at scale, there will almost certainly be a server caching layer
        implemented. For example, varnish or fastly, to name just a couple
      </li>
      <li>
        The server caching layer acts to resolve all the requests that it has
        seen before, so multiple users being on a category page, that is
        automatically pre-fetching the next page of products, will onlly hit the
        app server once, with the cache layer serving the response for all other
        users
      </li>
      <li>
        Out of scope of this talk, but just quickly, the reason the data in this
        caching layer doesn't go stale is because it can be selectively clear,
        for example, when prices have been updated, product relative information
        in the caching layer can be programmatically purged, so the next request
        will hit the server
      </li>
    </aside>
  </section>
</section>